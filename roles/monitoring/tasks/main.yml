---
# Monitoring Role - Main Tasks with Cinder Volume Support
# Deploys Prometheus, Grafana, and full monitoring stack on master node
# Supports both Cinder partitioned volumes and local-path provisioner

- name: Wait for all cluster nodes to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}' | grep -c "True" || echo "0"
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: ready_nodes
  until: ready_nodes.stdout|int >= 1
  retries: 30
  delay: 20
  changed_when: false

- name: Wait for CoreDNS pods to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl wait --for=condition=Ready pods -l k8s-app=kube-dns -n kube-system --timeout=180s || true
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  retries: 2
  delay: 20
  ignore_errors: yes
  changed_when: false

- name: Check if Helm is installed
  shell: command -v helm
  register: helm_check
  changed_when: false
  failed_when: false

- name: Download and install Helm
  shell: |
    curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
  when: helm_check.rc != 0
  retries: 3
  delay: 10

- name: Verify Helm installation
  shell: helm version --short
  register: helm_version
  changed_when: false

- name: Display Helm version
  debug:
    var: helm_version.stdout

- name: Add Prometheus Community Helm repository
  become: yes
  become_user: ubuntu
  shell: |
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  changed_when: false
  retries: 3
  delay: 10

- name: Update Helm repositories
  become: yes
  become_user: ubuntu
  shell: |
    helm repo update
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  changed_when: false
  retries: 3
  delay: 10

- name: Create monitoring namespace
  become: yes
  become_user: ubuntu
  shell: |
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  changed_when: false

- name: Check if using Cinder storage
  set_fact:
    using_cinder: "{{ use_cinder | default(false) }}"
    cinder_storage_path: "{{ storage_path | default('/mnt/k8s-storage') }}"
    storage_class_name: "{{ 'manual' if (use_cinder | default(false)) else 'local-path' }}"

- name: Display storage configuration
  debug:
    msg:
      - "Using Cinder: {{ using_cinder }}"
      - "Storage Path: {{ cinder_storage_path }}"
      - "StorageClass: {{ storage_class_name }}"

# === CINDER STORAGE SETUP ===
- name: Create Persistent Volumes for Cinder storage
  become: yes
  become_user: ubuntu
  shell: |
    cat <<EOF | kubectl apply -f -
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: prometheus-pv
    spec:
      capacity:
        storage: 15Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      storageClassName: manual
      hostPath:
        path: {{ cinder_storage_path }}/prometheus
        type: DirectoryOrCreate
      nodeAffinity:
        required:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - k8s-master
    ---
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: grafana-pv
    spec:
      capacity:
        storage: 5Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      storageClassName: manual
      hostPath:
        path: {{ cinder_storage_path }}/grafana
        type: DirectoryOrCreate
      nodeAffinity:
        required:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - k8s-master
    ---
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: alertmanager-pv
    spec:
      capacity:
        storage: 5Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      storageClassName: manual
      hostPath:
        path: {{ cinder_storage_path }}/alertmanager
        type: DirectoryOrCreate
      nodeAffinity:
        required:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - k8s-master
    EOF
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  when: using_cinder | bool
  changed_when: false

# === LOCAL-PATH PROVISIONER SETUP (fallback) ===
- name: Check if local-path storage provisioner exists
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get deployment -n local-path-storage local-path-provisioner 2>/dev/null || echo "not_found"
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: storage_check
  changed_when: false
  when: not (using_cinder | bool)

- name: Install local-path storage provisioner
  become: yes
  become_user: ubuntu
  shell: |
    kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.28/deploy/local-path-storage.yaml
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  when:
    - not (using_cinder | bool)
    - "'not_found' in storage_check.stdout"
  retries: 3
  delay: 10

- name: Wait for local-path-provisioner to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl wait --for=condition=Ready pod -l app=local-path-provisioner -n local-path-storage --timeout=120s
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  when:
    - not (using_cinder | bool)
    - "'not_found' in storage_check.stdout"
  retries: 2
  delay: 10
  ignore_errors: yes

- name: Set local-path as default StorageClass
  become: yes
  become_user: ubuntu
  shell: |
    kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  when:
    - not (using_cinder | bool)
    - "'not_found' in storage_check.stdout"
  changed_when: false
  ignore_errors: yes

# === PROMETHEUS HELM VALUES ===
- name: Create custom values file for Prometheus stack
  copy:
    dest: /tmp/prometheus-values.yaml
    content: |
      # Prometheus Operator Configuration
      prometheusOperator:
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
      
      # Prometheus Configuration
      prometheus:
        prometheusSpec:
          retention: 7d
          resources:
            requests:
              cpu: 200m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
          storageSpec:
            volumeClaimTemplate:
              spec:
                storageClassName: {{ storage_class_name }}
                accessModes: ["ReadWriteOnce"]
                resources:
                  requests:
                    storage: 10Gi
      
      # Grafana Configuration
      grafana:
        enabled: true
        adminPassword: admin
        service:
          type: NodePort
          nodePort: 30080
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        persistence:
          enabled: true
          storageClassName: {{ storage_class_name }}
          size: 4Gi
      
      # AlertManager Configuration
      alertmanager:
        alertmanagerSpec:
          retention: 120h
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
          storage:
            volumeClaimTemplate:
              spec:
                storageClassName: {{ storage_class_name }}
                accessModes: ["ReadWriteOnce"]
                resources:
                  requests:
                    storage: 4Gi
      
      # Node Exporter Configuration
      nodeExporter:
        enabled: true
      
      # Kube State Metrics Configuration
      kubeStateMetrics:
        enabled: true
      
      # Disable components not needed in small clusters
      kubeControllerManager:
        enabled: false
      kubeScheduler:
        enabled: false
      kubeProxy:
        enabled: true
      kubeEtcd:
        enabled: false
    owner: ubuntu
    group: ubuntu
    mode: '0644'

- name: Check if Prometheus stack is already installed
  become: yes
  become_user: ubuntu
  shell: |
    helm list -n monitoring | grep prometheus || echo "not_installed"
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: prometheus_installed
  changed_when: false

- name: Install Prometheus Stack using Helm
  become: yes
  become_user: ubuntu
  shell: |
    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
      --namespace monitoring \
      --create-namespace \
      --values /tmp/prometheus-values.yaml \
      --wait \
      --timeout 20m
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  when: "'not_installed' in prometheus_installed.stdout"
  register: helm_install
  async: 1800
  poll: 10
  retries: 2
  delay: 30
  ignore_errors: yes

- name: Wait for Prometheus Operator to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl wait --for=condition=Available --timeout=600s deployment/prometheus-kube-prometheus-operator -n monitoring
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  retries: 3
  delay: 30
  ignore_errors: yes

- name: Wait for Prometheus pods to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl wait --for=condition=Ready --timeout=600s pods -l app.kubernetes.io/name=prometheus -n monitoring
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  retries: 3
  delay: 30
  ignore_errors: yes

- name: Wait for Grafana pods to be ready
  become: yes
  become_user: ubuntu
  shell: |
    kubectl wait --for=condition=Ready --timeout=600s pods -l app.kubernetes.io/name=grafana -n monitoring
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  retries: 3
  delay: 30
  ignore_errors: yes

- name: Get Grafana admin password
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: grafana_password
  changed_when: false

- name: Get Grafana service details
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get svc -n monitoring prometheus-grafana -o jsonpath='{.spec.type}:{.spec.ports[0].nodePort}'
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: grafana_service
  changed_when: false

- name: Get Prometheus service details
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get svc -n monitoring prometheus-kube-prometheus-prometheus
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: prometheus_service
  changed_when: false

- name: Display monitoring stack information
  debug:
    msg:
      - "========================================="
      - "Monitoring Stack Deployment Complete!"
      - "========================================="
      - "Storage Type: {{ 'Cinder Partitioned' if using_cinder else 'Local-Path' }}"
      - "Storage Class: {{ storage_class_name }}"
      - ""
      - "Grafana Access:"
      - "  - Service Type: {{ grafana_service.stdout.split(':')[0] }}"
      - "  - NodePort: {{ grafana_service.stdout.split(':')[1] }}"
      - "  - Username: admin"
      - "  - Password: {{ grafana_password.stdout }}"
      - ""
      - "Access Grafana:"
      - "  kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80"
      - "  Then browse to: http://localhost:3000"
      - ""
      - "Access Prometheus:"
      - "  kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090"
      - "  Then browse to: http://localhost:9090"
      - ""
      - "View all monitoring pods:"
      - "  kubectl get pods -n monitoring"
      - "========================================="

- name: Create monitoring dashboard ConfigMap
  become: yes
  become_user: ubuntu
  shell: |
    kubectl create configmap monitoring-info -n monitoring \
      --from-literal=grafana-password="{{ grafana_password.stdout }}" \
      --from-literal=storage-type="{{ 'Cinder' if using_cinder else 'Local-Path' }}" \
      --from-literal=access-info="Port-forward with: kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80" \
      --dry-run=client -o yaml | kubectl apply -f -
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  changed_when: false

- name: Verify all monitoring components are running
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get pods -n monitoring -o wide
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: monitoring_pods
  changed_when: false

- name: Display monitoring pods status
  debug:
    var: monitoring_pods.stdout_lines

- name: Display storage information (Cinder only)
  become: yes
  become_user: ubuntu
  shell: |
    kubectl get pv,pvc -n monitoring
  environment:
    KUBECONFIG: /home/ubuntu/.kube/config
  register: storage_info
  changed_when: false
  when: using_cinder | bool

- name: Show storage details
  debug:
    var: storage_info.stdout_lines
  when: using_cinder | bool
